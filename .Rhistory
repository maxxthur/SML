X <- mvrnorm(n = 100, mu = rep(0, 200), Sigma = diag(1, nrow = 200, ncol = 200))
names(X) <- paste0("X", 1:100)
names(X) <- paste0("X", 1:200)
# b) use 10 first columns of X and simulated noise to get y
y <- apply(X[, 1:10], MARGIN = 1, FUN = sum) + rnorm(100, mean = 0, sd = sqrt(0.01))
library(glmnet)
RIDGE <- glmnet(x = X, y = y, alpha = 0)
LASSO <- glmnet(x = X, y = y, alpha = 1)
# d) plot for RIDGE
plot(RIDGE)
library(MASS)
library(MASS)
set.seed(123)
# a) draw from standard multivariate normal
X <- mvrnorm(n = 100, mu = rep(0, 100), Sigma = diag(1, nrow = 100, ncol = 100))
names(X) <- paste0("X", 1:100)
# b) use 10 first columns of X and simulated noise to get y
y <- apply(X[, 1:10], MARGIN = 1, FUN = sum) + rnorm(100, mean = 0, sd = sqrt(0.01))
library(glmnet)
RIDGE <- glmnet(x = X, y = y, alpha = 0)
LASSO <- glmnet(x = X, y = y, alpha = 1)
LASSO <- glmnet(x = X, y = y, alpha = 1)
```{r}
# d) plot with xvar = lambda
plot(RIDGE, xvar = "lambda")
# d) plot for RIDGE
plot(RIDGE)
# d) plot for RIDGE
plot(RIDGE)
# d) plot for LASSO
plot(LASSO)
?glmnet
RIDGE
# d) plot with xvar = lambda
plot(RIDGE, xvar = "lambda")
# d) plot with xvar = lambda
plot(RIDGE, xvar = "lambda")
# d) plot for LASSO
plot(LASSO)
# d) plot with xvar = lambda
plot(LASSO, xvar = "lambda")
log(1)
predict(LASSO, "nonzero")
predict(LASSO,type =  "nonzero")
plot(LASSO, xvar = "deviance")
plot(LASSO, xvar = "dev")
# get deviance and lambda
RIDGE_dev_l <- data.frame(deviance = deviance(RIDGE), lambda = RIDGE$lambda)
LASSO_dev_l <- data.frame(deviance = deviance(LASSO), lambda = LASSO$lambda)
with(LASSO_dev_l, plot(x = lambda, y = deviance, type = "l"))
plot(LASSO, xvar = "dev")
# get number of non-zero coefficients and lambda
# step 1 extract coefficients. Rows are Variables, columns correspond to lambda
RIDGE_coef <- coef(RIDGE)
LASSO_coef <- coef(LASSO)
# define an effective 0 as .Machine$double.eps and treat everything smaller as 0
# column sum of logical matrix provides number of non zero coefficients
RIDGE_coef_non_zero <- apply(abs(RIDGE_coef) > .Machine$double.eps, MARGIN = 2, sum)
LASSO_coef_non_zero <- apply(abs(LASSO_coef) > .Machine$double.eps, MARGIN = 2, sum)
RIDGE_coef_non_zero
LASSO_coef_non_zero
predict(LASSO, type = "nonzero")
predict(LASSO, type = "nonzero") %>% length()
lapply(predict(LASSO, type = "nonzero"), length)
# get number of non-zero coefficients and lambda
RIDGE_nz <- predict(RIDGE, type = "nonzero")
# get number of non-zero coefficients and lambda
RIDGE_nz <- lapply(predict(RIDGE, type = "nonzero"), length)
RIDGE_nz
# get number of non-zero coefficients and lambda
RIDGE_nz <- unlist(lapply(predict(RIDGE, type = "nonzero"), length))
RIDGE_nz
LASSO_nz <- unlist(lapply(predict(LASSO, type = "nonzero"), length))
# plot deviance in dependence of lambda
with(RIDGE_dev_l, plot(x = lambda, y = deviance, type = "l"))
with(LASSO_dev_l, plot(x = lambda, y = deviance, type = "l"))
# get deviance and lambda
RIDGE_dev_l <- data.frame(deviance = deviance(RIDGE), lambda = RIDGE$lambda)
LASSO_dev_l <- data.frame(deviance = deviance(LASSO), lambda = LASSO$lambda)
# get number of non-zero coefficients and lambda
RIDGE_nz <- unlist(lapply(predict(RIDGE, type = "nonzero"), length))
LASSO_nz <- unlist(lapply(predict(LASSO, type = "nonzero"), length))
# plot deviance in dependence of lambda for RIDGE
with(RIDGE_dev_l, plot(x = lambda, y = deviance, type = "l"))
# plot number of non-zeros in dependence of lambda for RIDGE
plot(x = RIDGE$lambda, y = RIDGE_nz, type = "l")}
par(mfrow = c(1, 2))
{
par(mfrow = c(1, 2))
# plot deviance in dependence of lambda for RIDGE
with(RIDGE_dev_l, plot(x = lambda, y = deviance, type = "l"))
# plot number of non-zeros in dependence of lambda for RIDGE
plot(x = RIDGE$lambda, y = RIDGE_nz, type = "l")
}
# plot number of non-zeros in dependence of lambda for RIDGE
plot(x = LASSOlambda, y = LASSO_nz, type = "l")
{
par(mfrow = c(1, 2))
# plot deviance in dependence of lambda for RIDGE
with(LASSO_dev_l, plot(x = lambda, y = deviance, type = "l"))
# plot number of non-zeros in dependence of lambda for RIDGE
plot(x = LASSOlambda, y = LASSO_nz, type = "l")
}
{
par(mfrow = c(1, 2))
# plot deviance in dependence of lambda for RIDGE
with(LASSO_dev_l, plot(x = lambda, y = deviance, type = "l"))
# plot number of non-zeros in dependence of lambda for RIDGE
plot(x = LASSO$lambda, y = LASSO_nz, type = "l")
}
knitr::opts_chunk$set(echo = TRUE)
suppressMessages(library("ISLR2"))
suppressMessages(library("ggplot2"))
suppressMessages(library("gridExtra"))
suppressMessages(library("dplyr"))
set.seed(7362)
data("Default", package="ISLR2")
df=Default
#First, we need to convert the 'default' and 'student' variables into the
#binary format. "Yes"=1, "No"=0.
df$default = as.integer(ifelse(df$default == "Yes", 1, 0))
df$student = as.integer(ifelse(df$student == "Yes", 1, 0))
#We create an empty dataframe to store the results.
df_results = data.frame(matrix(ncol=3,nrow=100,
dimnames=list(NULL,
c("val_set_error",
"false_neg", "def_ratio"))))
# a)
glmfit_a = glm(default ~ income + balance, data = df, family =
binomial(link = "logit"))
print(summary(glmfit_a))
# b)
#Train-set split (70% train-30% test)
df$id = 1:nrow(df)
train = df %>% dplyr::sample_frac(0.70)
test = dplyr::anti_join(df, train, by = 'id')
# Training the logistic regression model
glmfit_b = glm(default ~ income + balance, data = train, family =
binomial(link = "logit"))
print(summary(glmfit_b))
# Getting the predictions for the test dataset
preds_test = predict(glmfit_b,test, type = "response")
#Since we get the probabilities with the regression model, we used a 0.5
#threshold.
preds = ifelse(preds_test>0.5, 1, 0)
#To compute the validation set error and false positive ratio we use the
#confusion matrix.
temp = table(test$default, preds)
print(temp)
#Misclassification rate, false negative ratio and default ratio
#calculations are stored in the dataframe.
val_set_error = (temp[2]+temp[3])/sum(temp)
false_neg = temp[2]/sum(temp)
def_ratio = sum(test$default)/sum(temp)
paste("Misclassification rate:",val_set_error)
paste("False negative rate:",false_neg)
paste("Default ratio:",def_ratio)
# c)
#We repeat the process 100 times using 100 different splits.
for(i in 1:100) {
#Train-set split (70% train-30% test)
df$id = 1:nrow(df)
train = df %>% dplyr::sample_frac(0.70)
test = dplyr::anti_join(df, train, by = 'id')
# Training the logistic regression model
glmfit = glm(default ~ income + balance, data = train, family =
binomial(link = "logit"))
# Getting the predictions for the test dataset
preds_test = predict(glmfit,test, type = "response")
#Since we get the probabilities with the regression model, we used a 0.5
#threshold.
preds = ifelse(preds_test>0.5, 1, 0)
#To compute the validation set error and false positive ratio we use the
#confusion matrix.
temp = table(test$default, preds)
#Misclassification rate, false negative ratio and default ratio
#calculations are stored in the dataframe.
df_results$val_set_error[i] = (temp[2]+temp[3])/sum(temp)
df_results$false_neg[i] = temp[2]/sum(temp)
df_results$def_ratio[i] = sum(test$default)/sum(temp)
}
# Creating the plots
val_set_error_plot = ggplot(df_results, aes(x=def_ratio, y=val_set_error)) +
geom_point() +
geom_smooth(method=lm , color="orange", se=FALSE) +
labs(title = "Validation Set Error vs. Default Ratio",
x = "Default Ratio of the Test Dataset",
y = "Validation Set Error") +
theme(plot.title = element_text(size=11))
false_neg_plot = ggplot(df_results, aes(x = def_ratio, y = false_neg)) +
geom_point() +
geom_smooth(method=lm , color="orange", se=FALSE) +
labs(title = "False Negative Rate vs. Default Ratio",
x = "Default Ratio of the Test Dataset",
y = "False Negative Rate") +
theme(plot.title = element_text(size=11))
grid.arrange(val_set_error_plot, false_neg_plot, nrow = 1)
knitr::opts_chunk$set(echo = TRUE)
set.seed(1)
x <- rnorm(100)
y <- x - 2*x^2 + rnorm(100)
# assuming you dont mean orthogonal polynomials we set up a data.frame with all the polynomials inside
dat <- data.frame(y = y, x = x, x2 = x^2, x3 = x^3,x =  x^4)
dim(dat)
fits <- lapply(2:5, function(i) {
lm(data = dat[, 1:i], y ~ .)
})
fits
# assuming you dont mean orthogonal polynomials we set up a data.frame with all the polynomials inside
dat <- data.frame(y = y, x = x, x2 = x^2, x3 = x^3, x4 = x^4)
fits <- lapply(2:5, function(i) {
lm(data = dat[, 1:i], y ~ .)
})
fits
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggthemes)
dat %>%
ggplot(aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "loess")
dat %>%
ggplot(aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "loess") +
theme_base()
dat %>%
ggplot(aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "loess", se = F) +
theme_base()
K <- lapply(fits$coef, length)
K
K <- lapply(fits, function(f) length(f$coef))
K
K <- unlist(lapply(fits, function(f) length(f$coef))) + 1
K
# get the LogLikelihood of the models
LL <- unlist(lapply(fits, logLik))
LL
# AIC
AIC <- 2K - 2*LL
# AIC
AIC <- 2*K - 2*LL
AIC
which.min(AIC)
# print model summary with for lowest AIC
summary(fits[[which.min(AIC)]])
# d)
# create 100 test data sets
data <- lapply(1:100, function(i) {
x <- rnorm(100)
y <- x - 2*x^2 + rnorm(100)
data.frame(y = y, x = x, x2 = x^2, x3 = x^3, x4 = x^4)
})
data
data[[1]] == data[[2]]
# d)
# create 100 test data sets
new_y <- lapply(1:100, function(i) {
x <- rnorm(100)
y <- x - 2*x^2 + rnorm(100)
cbind(data.frame(y = y), dat[, 2:5]) # add X from a-c to the new response
})
new_y[[1]]
?logLik()
fits[[1]]
summary(fits[[1]])
test <- summary(fits[[1]])
test$sigma
?predict.lm
fits[[1]]
fits[[1]]$fitted.values
sigma_c <- lapply(fits, function(f) f$sigma)
sigma_c
sigma_c <- lapply(fits, function(f) summary(f)$sigma)
sigma_c
lapply(fits, function(f) f$residuals^2 / length(f$residuals))
lapply(fits, function(f) sum(f$residuals^2) / length(f$residuals))
lapply(fits, function(f) sqrt(sum(f$residuals^2) / length(f$residuals)))
# get fitted values from models in c
pred_c <- lapply(fits, function(f) f$fitted)
sigma_c <- lapply(fits, function(f) summary(f)$sigma)
lapply(fits, function(f) sqrt(sum(f$residuals^2) / length(f$residuals)))
pred_c
sigma_c
lapply(fits, function(f) sqrt(sum(f$residuals^2) / length(f$residuals)))
lapply(fits, function(f) sd(f$residuals))
# get fitted values from models in c
pred_c <- lapply(fits, function(f) f$fitted)
# get residual standard deviation
sigma_c <- lapply(fits, function(f) summary(f)$sigma)
# create 100 test data sets
new_y <- lapply(1:100, function(i) {
x <- rnorm(100)
y <- x - 2*x^2 + rnorm(100)
y
})
new_y
pred_c
rnorm(n = 1, mean = c(0, 1), sd = c(1, 2))
rnorm(n = 2, mean = c(0, 1), sd = c(1, 2))
rnorm(n = 2, mean = c(0, 100), sd = c(1, 2))
dnorm(n = c(0, 100), mean = c(0, 100), sd = c(1, 2))
dnorm(q = c(0, 100), mean = c(0, 100), sd = c(1, 2))
dnorm(x = c(0, 100), mean = c(0, 100), sd = c(1, 2))
dnorm(x = c(0, 100), mean = c(0, 100), sd = c(1, 2))
dnorm(x = 100, mean = 100, sd = 2)
lapply(new_y, function(ny) {
dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])
})
lapply(new_y, function(ny) {
log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]]))
})
lapply(new_y, function(ny) {
sum(log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])))
})
AIC
lapply(new_y, function(ny) {
mean(log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])))
})
lapply(new_y, function(ny) {
mean(2* -log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])))
})
lapply(new_y, function(ny) {
- 2* mean(log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])))
})
sum(log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])))
lapply(new_y, function(ny) {
sum(log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])))
})
# get fitted values from models in c
pred_c <- lapply(fits, function(f) f$fitted)
# get residual standard deviation
sigma_c <- lapply(fits, function(f) summary(f)$sigma)
# create 100 test data sets
new_y <- lapply(1:100, function(i) {
y <- x - 2*x^2 + rnorm(100)
y
})
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)0
# get residual standard deviation
sigma_c <- lapply(fits, function(f) summary(f)$sigma)
library(tidyverse)
library(tidyverse)
library(ggthemes)
# a)
# data
set.seed(1)
x <- rnorm(100)
y <- x - 2*x^2 + rnorm(100)
# assuming you dont mean orthogonal polynomials we set up a data.frame with all the polynomials inside
dat <- data.frame(y = y, x = x, x2 = x^2, x3 = x^3, x4 = x^4)
dat %>%
ggplot(aes(x = x, y = y)) +
geom_point() +
geom_smooth(method = "loess", se = F) +
theme_base()
# fit the models
fits <- lapply(2:5, function(i) {
lm(data = dat[, 1:i], y ~ .)
})
# calculate AIC stepwise
# A get number of coefficients + 1 (we estimate the variance in addition)
K <- unlist(lapply(fits, function(f) length(f$coef))) + 1
# get the LogLikelihood of the models
LL <- unlist(lapply(fits, logLik))
# AIC
AIC <- 2*K - 2*LL
AIC
# print model summary with for lowest AIC
summary(fits[[which.min(AIC)]])
# fit the models
fits <- lapply(2:5, function(i) {
lm(data = dat[, 1:i], y ~ .)
})
# calculate AIC stepwise
# A get number of coefficients + 1 (we estimate the variance in addition)
K <- unlist(lapply(fits, function(f) length(f$coef))) + 1
# get the LogLikelihood of the models
LL <- unlist(lapply(fits, logLik))
# AIC
AIC <- 2*K - 2*LL
AIC
# print model summary with for lowest AIC
summary(fits[[which.min(AIC)]])
# get fitted values from models in c
pred_c <- lapply(fits, function(f) f$fitted)
# get residual standard deviation
sigma_c <- lapply(fits, function(f) summary(f)$sigma)
# create 100 test data sets
new_y <- lapply(1:100, function(i) {
y <- x - 2*x^2 + rnorm(100)
y
})
lapply(new_y, function(ny) {
log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]]))
})
sum(log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])))
lapply7(new_y, function(ny) {
sum(log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])))
})
lapply7(new_y, function(ny) {
sum(log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])))
})
lapply(new_y, function(ny) {
sum(log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])))
})
lapply(new_y, function(ny) {
sum(log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])))
})
LL <- lapply(new_y, function(ny) {
sum(log(dnorm(x = ny, mean = pred_c[[2]], sd = sigma_c[[2]])))
})
err <- mean(-2 * unlist())
err <- mean(-2 * unlist(LL))
err
# try first for the best model:
Loss <- rep(NA, 4)
Loss
# try first for the best model:
Err <- rep(NA, 4)
for(i in length(pred_c)) {
LL <- lapply(new_y, function(ny) {
sum(log(dnorm(x = ny, mean = pred_c[[i]], sd = sigma_c[[i]])))
})
Err[i] <- -2 * mean(unlist(LL))
}
# d)
# get fitted values from models in c
pred_c <- lapply(fits, function(f) f$fitted)
# get residual standard deviation
sigma_c <- lapply(fits, function(f) summary(f)$sigma)
# create 100 test data sets
new_y <- lapply(1:100, function(i) {
y <- x - 2*x^2 + rnorm(100)
y
})
# now the assumption is that errors in linear regression are gaussian hence
# the likelihood must be that of a gaussian distribution
# try first for the best model:
Err <- rep(NA, 4)
for(i in length(pred_c)) {
LL <- lapply(new_y, function(ny) {
sum(log(dnorm(x = ny, mean = pred_c[[i]], sd = sigma_c[[i]])))
})
Err[i] <- -2 * mean(unlist(LL))
}
# print results
Err
# print results
Err
# try first for the best model:
Err <- rep(NA, 4)
for(i in 1:length(pred_c)) {
LL <- lapply(new_y, function(ny) {
sum(log(dnorm(x = ny, mean = pred_c[[i]], sd = sigma_c[[i]])))
})
Err[i] <- -2 * mean(unlist(LL))
}
# print results
Err
x <- rnorm(40, mean = 0, sd = 2)
noise <- rnorm(40, mean = 0, sd = 3)
y <- x + x^2 + noise
lm(y ~ x + x^2)
x <- rnorm(40, mean = 0, sd = 1)
noise <- rnorm(40, mean = 0, sd = 1)
y <- x + x^2 + noise
lm(y ~ x + x^2)
summary(lm(y ~ x + x^2))
summary(lm(y ~ x + I(x^2)))
x <- rnorm(40, mean = 0, sd = 1)
noise <- rnorm(40, mean = 0, sd = 1)
y <- x + x^2 + noise
x <- rnorm(40, mean = 0, sd = 1)
x2 <- x^2
noise <- rnorm(40, mean = 0, sd = 1)
y <- x + x2 + noise
summary(lm(y ~ x + x^2))
summary(lm(y ~ x + x2))
x <- rnorm(40, mean = 0, sd = 2)
x2 <- x^2
noise <- rnorm(40, mean = 0, sd = 3)
y <- x + x2 + noise
summary(lm(y ~ x + x2))
x <- rnorm(40, mean = 0, sd = 1)
x2 <- x^2
noise <- rnorm(40, mean = 0, sd = 1)
y <- x + x2 + noise
summary(lm(y ~ x + x2))
x <- rnorm(1000, mean = 0, sd = 1)
x2 <- x^2
noise <- rnorm(1000, mean = 0, sd = 1)
y <- x + x2 + noise
summary(lm(y ~ x + x2))
knitr::opts_chunk$set(echo = TRUE)
# As ElemStatLearn is not in CRAN anymore we must download the latest archived
# version and install it from our harddrive
if(require("ElemStatLearn") == F) print("nicht installiert")
install.packages()
?install.packages
# As ElemStatLearn is not in CRAN anymore we must download the latest archived
# version and install it from our harddrive
if(require("ElemStatLearn") == F) install.packages("ElemStatLearn_2015.6.26.1.tar.gz")
# As ElemStatLearn is not in CRAN anymore we must download the latest archived
# version and install it from our harddrive
if(require("ElemStatLearn") == F) install.packages("ElemStatLearn_2015.6.26.1.tar.gz")
# As ElemStatLearn is not in CRAN anymore we must download the latest archived
# version and install it from our harddrive
if(require("ElemStatLearn") == F) install.packages("ElemStatLearn_2015.6.26.1.tar.gz", repos = NULL)
